{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pdb\n",
    "from numpy import argmax\n",
    "import itertools \n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from unidecode import unidecode\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to the data txt file on disk.\n",
    "data_path = r'C:\\Users\\Rashi Budati\\Downloads\\Docsumo\\train_set.csv'\n",
    "data = pd.read_csv(data_path,encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23615 entries, 0 to 23614\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   23615 non-null  int64 \n",
      " 1   text    23615 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 369.1+ KB\n",
      "(23615, 2) None\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11121, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x :x.lower()).apply(lambda y: re.sub('[^A-Za-z0-9]+', ' ', y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels,labels_factors = pd.factorize(data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 85369090,\n",
       " 1: 33041000,\n",
       " 2: 87089900,\n",
       " 3: 73181500,\n",
       " 4: 85177090,\n",
       " 5: 85364900,\n",
       " 6: 85238090,\n",
       " 7: 84713010,\n",
       " 8: 39269099,\n",
       " 9: 85389000,\n",
       " 10: 87082900,\n",
       " 11: 85366990}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_text_to_id = {v:i for i,v in enumerate(labels_factors)}\n",
    "# len(labels_factors.tolist())\n",
    "id_to_label = {v:k for k,v in label_text_to_id.items()}\n",
    "id_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_file = r\"C:\\Users\\Rashi Budati\\Downloads\\Docsumo\\labels_for_classification.pckl\"\n",
    "f = open(labels_file,'wb')\n",
    "pickle.dump(labels_factors,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_name_list(name_list, max_len=None):\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences(list(map(featurise_name, name_list)), maxlen=max_len)\n",
    "\n",
    "def featurise_name(name):\n",
    "    name = unidecode(name)\n",
    "    numerical_name = list(map(ord, name))\n",
    "    return numerical_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_features = featurize_name_list(data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(column_features, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversample = RandomOverSampler(sampling_strategy='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over, y_over = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(127, 100))\n",
    "model.add(tf.keras.layers.LSTM(100))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(12,activation='softmax'))\n",
    "model.compile(\"adam\", \"sparse_categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 100)         12700     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1212      \n",
      "=================================================================\n",
      "Total params: 94,312\n",
      "Trainable params: 94,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "223/223 [==============================] - 35s 159ms/step - loss: 1.6899\n",
      "Epoch 2/15\n",
      "223/223 [==============================] - 36s 161ms/step - loss: 1.1930\n",
      "Epoch 3/15\n",
      "223/223 [==============================] - 36s 161ms/step - loss: 0.9734\n",
      "Epoch 4/15\n",
      "223/223 [==============================] - 34s 154ms/step - loss: 0.8442\n",
      "Epoch 5/15\n",
      "223/223 [==============================] - 35s 155ms/step - loss: 0.7532\n",
      "Epoch 6/15\n",
      "223/223 [==============================] - 35s 157ms/step - loss: 0.6785\n",
      "Epoch 7/15\n",
      "223/223 [==============================] - 35s 157ms/step - loss: 0.6288\n",
      "Epoch 8/15\n",
      "223/223 [==============================] - 35s 156ms/step - loss: 0.5898\n",
      "Epoch 9/15\n",
      "223/223 [==============================] - 36s 162ms/step - loss: 0.5624\n",
      "Epoch 10/15\n",
      "223/223 [==============================] - 35s 157ms/step - loss: 0.5048\n",
      "Epoch 11/15\n",
      "223/223 [==============================] - 36s 161ms/step - loss: 0.5130\n",
      "Epoch 12/15\n",
      "223/223 [==============================] - 37s 166ms/step - loss: 0.4485\n",
      "Epoch 13/15\n",
      "223/223 [==============================] - 35s 158ms/step - loss: 0.4238\n",
      "Epoch 14/15\n",
      "223/223 [==============================] - 40s 178ms/step - loss: 0.3935\n",
      "Epoch 15/15\n",
      "223/223 [==============================] - 38s 170ms/step - loss: 0.3645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14cc985a430>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_over, y_over, batch_size = 128, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8892123650222317\n",
      "Training report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9074    0.7705    0.8334      1983\n",
      "           1     0.9840    0.9877    0.9859      1305\n",
      "           2     0.8060    0.8766    0.8399      1370\n",
      "           3     0.9467    0.9230    0.9347      1636\n",
      "           4     0.9460    0.9381    0.9421      2037\n",
      "           5     0.8976    0.9513    0.9237      1355\n",
      "           6     0.9879    0.9590    0.9732      1365\n",
      "           7     0.9878    0.9953    0.9915      1054\n",
      "           8     0.6930    0.8080    0.7461      1729\n",
      "           9     0.8441    0.8392    0.8416      2375\n",
      "          10     0.8942    0.8896    0.8919      1150\n",
      "          11     0.8972    0.8480    0.8719      1533\n",
      "\n",
      "    accuracy                         0.8892     18892\n",
      "   macro avg     0.8993    0.8989    0.8980     18892\n",
      "weighted avg     0.8933    0.8892    0.8900     18892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy:\", metrics.accuracy_score(y_train, y_pred_train))\n",
    "print(\"Training report \\n\",classification_report(y_train, y_pred_train,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8536946855811984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8308    0.7231    0.7732       455\n",
      "           1     0.9638    0.9767    0.9702       300\n",
      "           2     0.7158    0.8647    0.7833       303\n",
      "           3     0.9112    0.9043    0.9077       397\n",
      "           4     0.9307    0.9136    0.9221       544\n",
      "           5     0.8747    0.9331    0.9030       359\n",
      "           6     0.9793    0.9324    0.9553       355\n",
      "           7     0.9644    0.9783    0.9713       277\n",
      "           8     0.6707    0.7174    0.6933       460\n",
      "           9     0.7869    0.8164    0.8014       561\n",
      "          10     0.8790    0.8206    0.8488       301\n",
      "          11     0.8602    0.7786    0.8174       411\n",
      "\n",
      "    accuracy                         0.8537      4723\n",
      "   macro avg     0.8640    0.8633    0.8622      4723\n",
      "weighted avg     0.8573    0.8537    0.8542      4723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_label = model.predict(X_test).argmax(axis=1)\n",
    "print(\"Test Accuracy:\", metrics.accuracy_score(y_test, predicted_label))\n",
    "print(classification_report(y_test, predicted_label,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18892, 114)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85389000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = \"module tm io relays digital io expansion module for plc tmdmr\"\n",
    "# features_test_text = featurize_name_list([test_text], max_len=114)\n",
    "id_to_label.get(model.predict(featurize_name_list([test_text], max_len=114)).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"text_classification_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = r\"C:\\Users\\Rashi Budati\\Downloads\\Docsumo\\test_set.csv\"\n",
    "test_data_df = pd.read_csv(test_data,encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5894, 1), Index(['text'], dtype='object'))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.shape, test_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rashi Budati\\anaconda3\\envs\\rashi\\lib\\site-packages\\tqdm\\std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5894/5894 [04:39<00:00, 21.10it/s]\n"
     ]
    }
   ],
   "source": [
    #"test_data_df['predicted_label'] = test_data_df['text'].progress_apply(lambda x:id_to_label.get(model.predict(featurize_name_list([x], max_len=114)).argmax()))"
    "label_predicted_test = model.predict(featurize_name_list(test_data_df["text"], max_len=114)).argmax(axis=1)"
     "test_data_df['predicted_label'] = pd.Series(label_predicted_test).apply(id_to_label.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_df.to_csv('Text_Classification_Output_file.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
